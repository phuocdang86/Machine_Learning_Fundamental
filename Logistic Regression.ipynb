{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e9c8a47-a995-4be4-b548-afef38a2e9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e9a0b31-0495-4375-b28e-1a0fbe1c3a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c3ca126f-adf0-4c9c-958d-bbd7cff113f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tanh(s):\n",
    "    return (np.exp(s) - np.exp(-s))/(np.exp(s) + np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f3fb705-e57f-4c0a-b9b5-7eb1f0d7d2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prob(w, X):\n",
    "    return sigmoid(X.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f936ee86-b3e9-4812-b4e4-ef15fb6f50cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(w, X, y, lam):\n",
    "    a = prob(w, X)\n",
    "    loss_0 = -np.mean(y * np.log(a) + (1-y)*np.log(1-a))\n",
    "    weight_decay = 0.5*lam/X.shape[0]*np.sum(w*w)\n",
    "    return loss_0 + weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a445a04-4b6d-4bb4-95b4-139cd8582c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(w_init, X, y, lam, lr =0.1, nepoches = 2000):\n",
    "    N, d = X.shape[0], X.shape[1]\n",
    "    w = w_old = w_init\n",
    "    \n",
    "    loss_hist = [loss(w_init, X, y, lam)]\n",
    "    ep = 0\n",
    "    while ep < nepoches:\n",
    "        ep += 1\n",
    "        mix_ids = np.random.permutation(N)\n",
    "        for i in mix_ids:\n",
    "            xi = X[i]\n",
    "            yi = y[i]\n",
    "            ai = sigmoid(xi.dot(w))\n",
    "            w = w - lr*((ai-yi)*xi + lam*w)\n",
    "            loss_hist.append(loss(w, X, y, lam))\n",
    "        if np.linalg.norm(w - w_old)/d < 1e-6:\n",
    "            break\n",
    "        w_old = w\n",
    "    return w, loss_hist\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ffc8ff0f-64b7-4a62-b5d2-2f9c1e7646a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution of Logistic Regression:  [ 1.0957152  -2.70574187]\n",
      "Final Loss:  0.42326681837295976\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "X = np.array([[0.5,0.75,1.0,1.25,1.50,1.75,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5,4.0,4.25,4.5,4.75,5.0,5.5]]).T\n",
    "y = np.array([0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1])\n",
    "\n",
    "Xbar = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1)\n",
    "w_init = np.random.randn(Xbar.shape[1])\n",
    "\n",
    "lam = 0.01\n",
    "w, loss_init = logistic_regression(w_init, Xbar, y, lam, lr = 0.05, nepoches = 500)\n",
    "print('Solution of Logistic Regression: ', w)\n",
    "print('Final Loss: ', loss(w, Xbar, y, lam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e28cfb-ba56-4751-9172-2d3074e3e751",
   "metadata": {},
   "source": [
    "# MNIST Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7cd199b-b687-41da-9dc5-11f76c81c09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuocdang/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  \"this URL: {}\".format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 70000 samples, each has 784 pixels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "mnist = fetch_openml('mnist_784', data_home = '../../data/')\n",
    "N,d = mnist.data.shape\n",
    "print('Total {:d} samples, each has {:d} pixels.'.format(N,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4508fd94-0c76-4656-96f4-3c692aae9343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/6s9v2z_j0b97d_435j2bjd9r0000gn/T/ipykernel_2073/1614860818.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X0.drop('label', axis = 1, inplace=True)\n",
      "/var/folders/w_/6s9v2z_j0b97d_435j2bjd9r0000gn/T/ipykernel_2073/1614860818.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X1.drop('label', axis = 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = mnist.data\n",
    "df['label'] = mnist.target\n",
    "\n",
    "# X_all = df.drop('label')\n",
    "# y_all = df['label']\n",
    "\n",
    "X0 = df[df['label'] == '0']\n",
    "X1 = df[df['label'] == '1']\n",
    "\n",
    "X0.drop('label', axis = 1, inplace=True)\n",
    "X1.drop('label', axis = 1, inplace=True)\n",
    "\n",
    "y0 = np.zeros(X0.shape[0])\n",
    "y1 = np.ones(X1.shape[0])\n",
    "\n",
    "X = np.concatenate((X0, X1), axis = 0)\n",
    "y = np.concatenate((y0, y1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "415112e0-e104-4a59-a1a4-d8bc9d33a4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "709681a6-cf87-40b8-b736-dada3088e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.80 %\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1e5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy %.2f %%' %(100*accuracy_score(y_test, y_pred.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9175f0-b770-4170-9591-c4de65dcef3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
